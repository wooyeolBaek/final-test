{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mhchoimmseg/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "2023-01-25 10:48:37.423711: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-25 10:48:37.429497: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200030000 Hz\n",
      "2023-01-25 10:48:37.431230: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55be3c184500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-01-25 10:48:37.431259: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "import os, cv2\n",
    "from facial_analysis import FacialImageProcessing\n",
    "\n",
    "\n",
    "imgProcessing = FacialImageProcessing()\n",
    "\n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "def process_face_image(src_file,dest_file):\n",
    "    try:\n",
    "        draw = cv2.imread(src_file)\n",
    "        img=cv2.cvtColor(draw,cv2.COLOR_BGR2RGB)\n",
    "        bounding_boxes, points = imgProcessing.detect_faces(img)\n",
    "        best_bb=[]\n",
    "        best_square=0\n",
    "        for b in bounding_boxes:\n",
    "            b=[int(bi) for bi in b]\n",
    "            #print(b,img.shape)\n",
    "            x1,y1,x2,y2=b[0:4]\n",
    "            if x2>x1 and y2>y1:\n",
    "                sq=(x2-x1)*(y2-y1)\n",
    "                if sq>best_square:\n",
    "                    best_square=sq\n",
    "                    best_bb=b\n",
    "        \n",
    "        if len(best_bb)!=0:\n",
    "            img_h,img_w,_=img.shape\n",
    "            face_x,face_y=best_bb[0],best_bb[1]\n",
    "            face_w,face_h=(best_bb[2]-best_bb[0]),(best_bb[3]-best_bb[1])\n",
    "            dw,dh=20,40#max(int(face_w*0.05),10),max(int(face_h*0.05),10)\n",
    "            #sz=max(face_w+2*dw,face_h+2*dh)\n",
    "            #dw,dh=(sz-face_w)//2,(sz-face_h)//2\n",
    "\n",
    "            box = (max(0,face_x-dw), max(0,face_y-dh), min(img_w,face_x+face_w+dw), min(img_h,face_y+face_h+dh))\n",
    "            \n",
    "            face_img=draw[box[1]:box[3],box[0]:box[2],:]\n",
    "            face_img = cv2.resize(face_img, TARGET_SIZE)\n",
    "            cv2.imwrite(dest_file,face_img)\n",
    "        else:\n",
    "            # print('No faces found for ', src_file)\n",
    "            return src_file\n",
    "            \n",
    "        \n",
    "        #print(src_file,dest_file)\n",
    "    except IOError:\n",
    "        print (\"cannot create facial image for '%s'\" % src_file)\n",
    "\n",
    "    except:\n",
    "        print(\"cannot read image \", src_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion = ['angry', 'anxiety', 'happy', 'hurt', 'neutral', 'sad', 'surprise']\n",
    "emotion = ['anxiety', 'happy', 'hurt', 'neutral', 'sad', 'surprise']\n",
    "root_dir = '/opt/ml/data/original'\n",
    "save_dir = '/opt/ml/data/detect_face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc = {\n",
    "    'angry':[],\n",
    "    'anxiety':[],\n",
    "    'happy':[],\n",
    "    'hurt':[],\n",
    "    'neutral':[],\n",
    "    'sad':[],\n",
    "    'surprise':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 7085/7408 [06:14<00:15, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot read image  /opt/ml/data/original/anxiety/.ipynb_anxiety_checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7408/7408 [06:32<00:00, 18.89it/s]\n",
      "100%|██████████| 7508/7508 [06:28<00:00, 19.30it/s]\n",
      "100%|██████████| 7422/7422 [06:13<00:00, 19.87it/s]\n",
      " 82%|████████▏ | 6094/7403 [05:05<01:09, 18.89it/s]"
     ]
    }
   ],
   "source": [
    "for emo in emotion:\n",
    "    emo_dir = os.path.join(root_dir, emo)\n",
    "    emo_save_dir = os.path.join(save_dir, emo)\n",
    "    if not os.path.exists(emo_save_dir):\n",
    "        os.makedirs(emo_save_dir)\n",
    "    for img in tqdm(os.listdir(emo_dir)):\n",
    "        ori = os.path.join(emo_dir, img)\n",
    "        det = os.path.join(emo_save_dir, img)\n",
    "        a = process_face_image(ori, det)\n",
    "        if a:\n",
    "            exc[emo].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emo in ['angry']:\n",
    "    emo_dir = os.path.join(root_dir, emo)\n",
    "    emo_save_dir = os.path.join(save_dir, emo)\n",
    "    if not os.path.exists(emo_save_dir):\n",
    "        os.makedirs(emo_save_dir)\n",
    "    for img in tqdm(os.listdir(emo_dir)):\n",
    "        ori = os.path.join(emo_dir, img)\n",
    "        det = os.path.join(emo_save_dir, img)\n",
    "        a = process_face_image(ori, det)\n",
    "        if a:\n",
    "            exc[emo].append(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhchoimmseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70ad9b5ba9a8cc87ed38c21fe5cd6429180f490f0b0df458fd355c792dae8675"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
